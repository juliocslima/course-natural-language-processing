{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5234573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-09 16:00:08--  https://lazyprogrammer.me/course_files/nlp/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving lazyprogrammer.me (lazyprogrammer.me)... 172.67.213.166, 104.21.23.210, 2606:4700:3031::6815:17d2, ...\n",
      "Connecting to lazyprogrammer.me (lazyprogrammer.me)|172.67.213.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1,5G) [application/x-gzip]\n",
      "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   1,53G  3,90MB/s    in 3m 4s   \n",
      "\n",
      "2022-06-09 16:03:12 (8,55 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://lazyprogrammer.me/course_files/nlp/GoogleNews-vectors-negative300.bin.gz\n",
    "\n",
    "# you are better off just downloading this from the source\n",
    "# https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "# https://code.google.com/archive/p/word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown https://drive.google.com/uc?0B7XkCwpI5KDYNlNUTTlSS21pQmM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eff075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5d6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9c77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(\n",
    "    'GoogleNews-vectors-negative300.bin',\n",
    "    binary = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903cc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogies(w1, w2, w3):\n",
    "    # w1 - w2 = ? - w3\n",
    "    # e.g. king - man = ? - woman\n",
    "    # ? = king - man + woman\n",
    "    r = word_vectors.most_similar(positive=[w1, w3], negative=[w2])\n",
    "    print(\"%s - %s = %s - %s\" % (w1, w2, r[0][0], w3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02077b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king - man = queen - woman\n"
     ]
    }
   ],
   "source": [
    "find_analogies('king', 'man', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09bf2858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france - paris = england - london\n"
     ]
    }
   ],
   "source": [
    "find_analogies('france', 'paris', 'london')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240080bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france - paris = italy - rome\n"
     ]
    }
   ],
   "source": [
    "find_analogies('france', 'paris', 'rome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d947d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris - france = lohan - italy\n"
     ]
    }
   ],
   "source": [
    "find_analogies('paris', 'france', 'italy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45d146e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france - french = england - english\n"
     ]
    }
   ],
   "source": [
    "find_analogies('france', 'french', 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b1441fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japan - japanese = tibet - chinese\n"
     ]
    }
   ],
   "source": [
    "find_analogies('japan', 'japanese', 'chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61b2621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japan - japanese = italy - italian\n"
     ]
    }
   ],
   "source": [
    "find_analogies('japan', 'japanese', 'italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fb4d35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "december - november = september - june\n"
     ]
    }
   ],
   "source": [
    "find_analogies('december', 'november', 'june')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75722b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miami - florida = dallas - texas\n"
     ]
    }
   ],
   "source": [
    "find_analogies('miami', 'florida', 'texas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ba1d171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "einstein - scientist = jude - painter\n"
     ]
    }
   ],
   "source": [
    "find_analogies('einstein', 'scientist', 'painter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5cac0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = he - she\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03bb3f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = uncle - aunt\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'aunt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a373ec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = brother - sister\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'sister')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68207ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = son - wife\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'wife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99dc75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = actor - actress\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae7aa23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man - woman = father - mother\n"
     ]
    }
   ],
   "source": [
    "find_analogies('man', 'woman', 'mother')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d3eb285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nephew - niece = uncle - aunt\n"
     ]
    }
   ],
   "source": [
    "find_analogies('nephew', 'niece', 'aunt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1692dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neigbors(w):\n",
    "    r = word_vectors.most_similar(positive=[w])\n",
    "    print(\"neighbors of: %s\" % w)\n",
    "    \n",
    "    for word, score in r:\n",
    "        print(\"\\t%s\" % word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc964b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: king\n",
      "\tkings\n",
      "\tqueen\n",
      "\tmonarch\n",
      "\tcrown_prince\n",
      "\tprince\n",
      "\tsultan\n",
      "\truler\n",
      "\tprinces\n",
      "\tPrince_Paras\n",
      "\tthrone\n"
     ]
    }
   ],
   "source": [
    "nearest_neigbors('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "277c5b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: france\n",
      "\tspain\n",
      "\tfrench\n",
      "\tgermany\n",
      "\teurope\n",
      "\titaly\n",
      "\tengland\n",
      "\teuropean\n",
      "\tbelgium\n",
      "\tusa\n",
      "\tserbia\n"
     ]
    }
   ],
   "source": [
    "nearest_neigbors('france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38dcc5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: japan\n",
      "\tjapanese\n",
      "\ttokyo\n",
      "\tamerica\n",
      "\teurope\n",
      "\tgermany\n",
      "\tchinese\n",
      "\tindia\n",
      "\thawaii\n",
      "\tusa\n",
      "\tkorea\n"
     ]
    }
   ],
   "source": [
    "nearest_neigbors('japan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba023102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: einstein\n",
      "\tnikki\n",
      "\tlmfao\n",
      "\talbert\n",
      "\tarmstrong\n",
      "\tjoan\n",
      "\tbecky\n",
      "\tmcmahon\n",
      "\tconrad\n",
      "\tlori\n",
      "\thaley\n"
     ]
    }
   ],
   "source": [
    "nearest_neigbors('einstein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eea83c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: girl\n",
      "\tboy\n",
      "\tteenage_girl\n",
      "\twoman\n",
      "\tteenager\n",
      "\tschoolgirl\n",
      "\tteenaged_girl\n",
      "\tdaughter\n",
      "\tmother\n",
      "\ttoddler\n",
      "\tgirls\n"
     ]
    }
   ],
   "source": [
    "nearest_neigbors('girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b696de50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: nephew\n",
      "\tson\n",
      "\tuncle\n",
      "\tbrother\n",
      "\tgrandson\n",
      "\tcousin\n",
      "\tfather\n",
      "\tniece\n",
      "\tyounger_brother\n",
      "\tnephews\n",
      "\tstepson\n"
     ]
    }
   ],
   "source": [
    "nearest_neigbors('nephew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93074a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: february\n",
      "\tjanuary\n",
      "\tapril\n",
      "\tseptember\n",
      "\tdecember\n",
      "\tjuly\n",
      "\toctober\n",
      "\tnovember\n",
      "\tjune\n",
      "\tfeb\n",
      "\tnorway\n"
     ]
    }
   ],
   "source": [
    "nearest_neigbors('february')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79dd1f4",
   "metadata": {},
   "source": [
    "### Exercise: download pretrained GloVe vectors from\n",
    "### https://nlp.stanford.edu/projects/glove/\n",
    "Implement your own ```find_analogies()``` and ```nearest_neighbors()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80fdc402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-09 16:28:44--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
      "--2022-06-09 16:28:45--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2176768927 (2,0G) [application/zip]\n",
      "Saving to: ‘glove.840B.300d.zip’\n",
      "\n",
      "glove.840B.300d.zip 100%[===================>]   2,03G  5,02MB/s    in 7m 0s   \n",
      "\n",
      "2022-06-09 16:35:45 (4,95 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://nlp.stanford.edu/data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47e89bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.840B.300d.zip\n",
      "  inflating: glove.840B.300d.txt     \n"
     ]
    }
   ],
   "source": [
    "!unzip glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d19b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 16:51:04.818355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-09 16:51:04.818384: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# code for Glove word embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5df79604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in dictionary= 6\n",
      "Dictionary is =  {'the': 1, 'text': 2, 'leader': 3, 'prime': 4, 'language': 5, 'natural': 6}\n"
     ]
    }
   ],
   "source": [
    "x = {'text', 'the', 'leader', 'prime',\n",
    "     'natural', 'language'}\n",
    "  \n",
    "# create the dict.\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x)\n",
    "  \n",
    "# number of unique words in dict.\n",
    "print(\"Number of unique words in dictionary=\", \n",
    "      len(tokenizer.word_index))\n",
    "print(\"Dictionary is = \", tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88bf4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_for_vocab(filepath, word_index,\n",
    "                        embedding_dim):\n",
    "    vocab_size = len(word_index) + 1\n",
    "      \n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix_vocab = np.zeros((vocab_size,\n",
    "                                       embedding_dim))\n",
    "  \n",
    "    with open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word]\n",
    "                embedding_matrix_vocab[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "  \n",
    "    return embedding_matrix_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98568ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix for vocab: word_index\n",
    "embedding_dim = 300\n",
    "embedding_matrix_vocab = embedding_for_vocab(\n",
    "    'data/glove.840B.300d.txt', tokenizer.word_index,\n",
    "  embedding_dim)\n",
    "  \n",
    "print(\"Dense vector for first word is => \",\n",
    "      embedding_matrix_vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_vocab[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
